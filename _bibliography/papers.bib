---
---

@article{yoon2024laserdex,
  title             = {LaserDex: Improvising Spatial Tasks Using Deictic Gestures and Laser Pointing for Human--Robot Collaboration in Construction},
  author            = {Yoon, Sungboo and Park, Moonseo and Ahn, Changbum R},
  journal           = {Journal of Computing in Civil Engineering},
  volume            = {38},
  number            = {3},
  pages             = {04024012},
  year              = {2024},
  publisher         = {American Society of Civil Engineers},
  doi               = {10.1061/JCCEE5.CPENG-5715},
  html              = {https://ascelibrary.org/doi/10.1061/JCCEE5.CPENG-5715},
  pdf               = {2405_JCCE.pdf},
  google_scholar_id = {W7OEmFMy1HYC},
  selected          = {true},
  additional_info   = {. **Editor's Choice**},
  abstract          = {In the context of the unstructured and fast-changing construction environment, the adaptability of robots to human improvisation is crucial. However, existing construction robots are limited in understanding spatial goals communicated spontaneously in the workplace and require substantial human-user training. Incorporating deictic gestures into human–robot interfaces holds promise for enhancing the intuitive operation of construction robots and for on-site collaboration. However, applying deictic gestures in precision-demanding construction tasks presents challenges because in a large-scale work environment, humans have limited accuracy in pointing at objects at a distance. This study introduces LaserDex, a novel interface for distant spatial tasking based on a global-to-local identification approach, in which the human first guides the robot toward the general area of the task using a deictic gesture and then indicates the precise area by dynamically using a laser pointer. Our user study with 11 participants demonstrated that LaserDex can achieve an intersection over union (IoU) of 0.830 when outlining a rectangular drywall opening (compared with an IoU of 0.514 for the baseline, a handheld controller), and an 11.4-mm distance error of the center of the estimated rectangle compared with the center of the targeted rectangle. The findings of this study underscore the potential of LaserDex to seamlessly combine intuitive human–robot interaction with precise robot operations.}
}

@article{yoon2023effects,
  title             = {Effects of Spatial Characteristics on the Human–Robot Communication Using Deictic Gesture in Construction},
  author            = {Yoon, Sungboo and Kim, YeSeul and Park, Moonseo and Ahn, Changbum R},
  journal           = {Journal of Construction Engineering and Management},
  volume            = {149},
  number            = {7},
  pages             = {04023049},
  year              = {2023},
  publisher         = {American Society of Civil Engineers},
  doi               = {10.1061/JCEMD4.COENG-12997},
  html              = {https://ascelibrary.org/doi/abs/10.1061/JCEMD4.COENG-12997},
  pdf               = {2307_JCEM.pdf},
  google_scholar_id = {qjMakFHDy7sC},
  selected          = {true},
  abstract          = {Construction robots are expected to frequently communicate in situ improvisations with human workers to adapt and change their workflow and methods. One way to achieve this is through deictic gestures that are one of the most effective forms of human–robot interaction (HRI) in delivering spatial information. Nevertheless, the limited coverage of deictic gestures in large-scale environments poses some challenges for both humans and robots in leveraging such techniques for HRI in construction. To identify the feasibility of deictic gestures in the construction domain and find applicable solutions for improving performance, this study aims to extend current knowledge on the performance in communicating positional information using deictic gestures by investigating the effects of spatial characteristics on spatial referencing, focusing on the target configuration, target distance, and relative position of human and robot. We observed that the recognition and estimation of deictic gestures were affected by the target plane, target position, and the target layout and that the robot performance was significantly reduced as the distance between the human and robot increased. The findings of this study demonstrate the challenges in spatial referencing within a large-scale environment and highlight the need for bidirectional communication in HRI.}
}

@inbook{yoon2024deictic,
  pdf               = {2401_i3CE.pdf},
  google_scholar_id = {Tyk-4Ss8FVUC},
  author            = {Yoon, Sungboo and Park, Jinsik and Park, Moonseo and Ahn, Changbum R},
  title             = {A Deictic Gesture-Based Human-Robot Interface for In Situ Task Specification in Construction},
  booktitle         = {Computing in Civil Engineering 2023},
  chapter           = {},
  year              = {2024},
  pages             = {445-452},
  doi               = {10.1061/9780784485224.054},
  url               = {https://ascelibrary.org/doi/abs/10.1061/9780784485224.054},
  eprint            = {https://ascelibrary.org/doi/pdf/10.1061/9780784485224.054},
  abstract          = { Despite the potential of robotic systems for automating the construction industry, the role of human operators remains essential for the success of these systems in complex and dynamic environments. However, current human-robot interfaces are often limited to low-level interactions that require constant micromanaging of robot movements. To address this limitation, this study proposes a deictic gesture-based interface that enables high-level task specification for construction robots. To evaluate the user experience and task performance of the proposed interface, we conducted a laboratory experiment with six human subjects who interacted with the robot to make openings in drywall panels. The results show that the proposed interface significantly reduced mental demand and effort levels among the participants compared to the conventional joystick interface. Moreover, task performance using the proposed interface was comparable in accuracy and efficiency to that achieved with the joystick interface. These findings highlight the potential of the proposed deictic gesture-based interface to facilitate intuitive human-robot interaction and precise operation of construction robots, particularly in situations where as-planned building models are not readily available. }
}

@inproceedings{yoon2021challenges,
  title             = {Challenges in deictic gesture-based spatial referencing for human-robot interaction in construction},
  author            = {Yoon, Sungboo and Kim, Yeseul and Ahn, Changbum R and Park, Moonseo},
  booktitle         = {ISARC. Proceedings of the International Symposium on Automation and Robotics in Construction},
  volume            = {38},
  pages             = {491--497},
  year              = {2021},
  organization      = {IAARC Publications},
  html              = {https://search.proquest.com/openview/2d94f48bf8606f66fc9f36669d3dfd83/1?pq-origsite=gscholar&cbl=1646340&casa_token=M0W_sGIFwfgAAAAA:EMg6q5Ldxk4FHqewVWSTsaaXzCi3N0wOsv7dpABz6A3HYT3OeyCQCOFGKVwdLwNLOlFLH3Pkbg},
  google_scholar_id = {2osOgNQ5qMEC},
  pdf               = {2111_ISARC.pdf},
  talk              = {https://www.youtube.com/watch?v=oktfEh3FvMg},
  abstract          = {As robots are envisioned to be deployed in construction job sites to work with humans, there is an increasing need for developing intuitive and natural communication between robots and humans. In particular, spatial information exchange is critical to navigating or delegating tasks to collaborative robots. However, such deictic gestures are inherently imprecise and ambiguous. Thus, it is challenging for robots to reason about the exact region of interest, especially in a cluttered large-scale construction environment. To address this limitation, this study evaluates the performance of spatial information exchange through the experiments based on pointing targets on the wall and ceiling, which are the most common workspaces in construction. We observed that the current deictic gesture-based method can estimate the pointed position on the wall and ceiling with a mean distance error of 0.767m, while the error tends to increase by 0.715m in the ceiling and 0.115m in the side panels. Our experimental results indicate that the deictic gesture-based method has some challenges in ceiling and side panel conditions, while the overall panel recognition shows acceptable performance. The findings of this study will help novice construction workers naturally and effectively communicate with robots by delivering spatial information on specific objects or regions in the shared workspace.}
}

@article{yoon2021multi,
  title             = {Multi-objective Optimization Model for Tower Crane Layout Planning in Modular Construction},
  author            = {Yoon, Sungboo and Park, Moonseo and Jung, Minhyuk and Hyun, Hosang and Ahn, Suho},
  journal           = {Korean Journal of Construction Engineering and Management},
  volume            = {22},
  number            = {1},
  pages             = {36--46},
  year              = {2021},
  publisher         = {Korea Institute of Construction Engineering and Management},
  doi               = {10.1061/JCEMD4.COENG-12997},
  html              = {https://koreascience.kr/article/JAKO202109554085158.page},
  pdf               = {2101_KJECM.pdf},
  google_scholar_id = {u-x6o8ySG0sC},
  selected          = {false},
  abstract          = {With an increasing trend toward high-rise modular construction, the simultaneous use of tower cranes at a modular construction site has recently been observed. Tower crane layout planning (TCLP) has a significant effect on cost, duration, safety and productivity of a project. In a modular construction project, particularly, poor decision about the layout of tower cranes is likely to have negative effects like additional employment of cranes and redesign, which will lead to additional costs and possible delays. It is, therefore, crucial to conduct thorough inspection of field conditions, lifting materials, tower crane capacity to make decisions on the layout of tower cranes. However, several challenges exist in planning for a multi-crane construction site in terms of safety and collaboration, which makes planning with experience and intuition complicated. This paper suggests a multi-objective optimization model for selection of the number of tower cranes, their models and locations, which minimizes cost and conflict. The proposed model contributes to the body of knowledge by showing the feasibility of using multi-objective optimization for TCLP decision-making process with consideration of trade-offs between cost and conflict.}
}

@inproceedings{Yoon2024evaluating,
  title             = {Evaluating Viewpoint Control Techniques in Virtual Reality Interface for Teleoperating Construction Welding Robots},
  author            = {Yoon, Sungboo and Shin, Seungmin and Lee, Sanghyun and Park, Moonseo and Ahn, Changbum R},
  editor            = {Riveiro, Belén and Arias, Pedro},
  booktitle         = {Proceedings of the 31st International Workshop on Intelligent Computing in Engineering},
  publisher         = {University of Vigo},
  institution       = {European Group for Intelligent Computing in Engineering(EG-ICE)},
  address           = {Vigo, Spain},
  pages             = {345--354},
  year              = {2024},
  pdf               = {2407_EG-ICE.pdf},
  google_scholar_id = {4TOpqqG69KYC},
  selected          = {false},
  poster            = {2404_ICRA.pdf},
  abstract          = {Effective visual feedback is critical for successful teleoperation of construction robots in remote locations. Recently, virtual reality (VR) has been leveraged to enhance teleoperation interfaces, providing enriched visualization and interaction capabilities. However, despite the critical role of viewpoints in 3D exploration and manipulation, the choice between coupled and decoupled viewpoints—where the user's camera is tethered or independent from the end-effector's position—in VR teleoperation interfaces for construction robots remains unclear. In this study, we explore the effect of viewpoint control technique in VR (coupled vs. decoupled viewpoint) on task performance, perceived workload, and perceived usability in the context of teleoperating welding robots in construction. Our comparative study with 10 participants demonstrated that under the coupled condition, participants completed the welding tasks significantly faster and with greater consistency across different locations when compared to the decoupled condition. These findings offer design implications for the integration of viewpoint control techniques in the development of visual interfaces for robotic teleoperation in construction.}
}